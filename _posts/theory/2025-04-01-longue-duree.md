---
title: longue durée
layout: article
origin: https://canmom.tumblr.com/post/779645001894379520/a-theme-in-art-that-fascinates-me-is-imagining-the
categories:
 - theory
excerpt: Personal identity considered over the potentially infinite future of (post)humanity.
tags:
 - don hertzfeldt
---
a theme in art that fascinates me is imagining the ultra-long-duration future of humanity, in which our forms become increasingly abstracted and strange to us.

i encountered pop-rock duo Zager and Evans’ song <cite>In the Year 2525</cite> from, naturally, a <cite>Fallout: New Vegas</cite> music mod. idk if this embed will work for you or if it gets copyright-slapped, you might have to click…

{% include youtube.html id="zKQfxi8V5FA" %}

…but anyway, it follows an imagined 10,000 year future of humanity in ~1010 year increments, projecting various things that might occur. its concerns are, naturally, terribly 1969: babies selected from the bottom of a ‘long glass tube’, behaviour-controlling pills, bodies atrophying because everything done by machines, at some point God shows up - not a mention of computers, they weren’t even on the horizon. the song has spawned numerous parodies and variants, from <a href="https://www.youtube.com/watch?v=HIy--pieleo&amp;pp=ygUQaW4gdGhlIHllYXIgMjUyNQ%3D%3D">a Jewish version</a> to the theme song of 90s American action show <cite><a href="https://www.youtube.com/watch?v=e2ZRSwul7cE&amp;pp=ygUaaW4gdGhlIHllYXIgMjUyNSBjbGVvcGF0cmE%3D">Cleopatra 2525</a></cite>.

I feel like what makes it work is the tone: the rising and falling minor arcs, the sense of resignation in the lyrics. far more than the specific scenarios imagined, which are a bit corny, there is that glimpse of the disorienting feeling that the forms we inhabit now are just an emphemeral passing phase, and how vast the possibility space of life could be.

<a href="https://en.wikipedia.org/wiki/Man_After_Man"><cite>Man After Man</cite></a> (1990) by Dougal Dixon takes another approach: using the tools of speculative biology, Dixon tries to imagine all sorts of strange hominids that could emerge out of us. you most likely know it from the <a href="https://knowyourmeme.com/memes/seasons-greetings-greasons">Seasons Greasons</a> meme, in which we become a screaming furry ape biting a larger, fluffier screaming ape. but Dixon has many weirder ideas. CM Kosemen went for a similar project in 2006 titled <a href="https://en.wikipedia.org/wiki/All_Tomorrows"><cite>All Tomorrows</cite></a>. I regret to say I have read neither of those books, so I’ll have to leave it at that.

of course, the GOAT on this subject is Don Hertzfeldt (who we visited way back on <a href="https://canmom.art/films/animation-night/89-don-hertzfeldt">AN89</a>). starting with his film <cite>The Meaning of Life</cite>, which I recently watched at the <a href="https://glasgowshort.org/">GSFF</a>, the long-term weird future of humanity became a recurring central theme in Hertzfeldt’s work.

{% include youtube.html id="qz9NTMtXV70" %}

Hertzfeldt’s film is almost entirely without dialogue. a huge variety of human characters walk across the screen to and fro; then the timeline accelerates and increasingly weird designs appear, interspersed with representation of timing of the solar system. at the end, two characters have a discussion in a nonsense language where only words that vaguely resemble 'meaning of life’ can be discerned. the larger character seems to scoff at the smaller one’s question, leaving the smaller staring out at the universe.

of course, the best-known version is probably that time he did an intro for the Simpsons, which speedruns a similar idea in about a minute and a half.

{% include youtube.html id="6i2l-LQ-dXI" %}

like with the eponymous phrase in <cite>The Meaning of Life</cite>, the film depicts some kind of heavily decayed signal being preserved even as everything else changes around it. it throws in a lot of <cite>Rejected</cite>-style surrealism for humour, but there’s still a core affirmation: 'still love you homar’, text reading 'I will never forget you’ - a willful absurdity in the face of everything else arounding it underlining that entropy will win and everything must become unrecognisable.

the substance of the theme becomes more concrete in Hertzfeldt’s three-part film <a href="https://vimeo.com/ondemand/itssuchabeautifulday/61349288"><cite>It’s Such A Beautiful Day</cite></a>, which tells the slow, relentless story of a character losing his memories, identity and cognitive abilities to dementia. to spoil the final moment of the film, which you should really watch… at the last minute, as it seems certain the character will finally die, the film - which has been entirely grounded so far - swerves into narrating the character’s immortality, outliving humanity and watching until the heat death of the universe. it is performed as a desperate and tragic choice by the narrator to switch into a different story, but it also serves to underline by its absurdity how all of our defining information <em>will</em> decohere and our fate is the same as Bob’s.

<aside>I won’t go into <cite>World of Tomorrow</cite> for now, though it is probably Hertzfeldt’s best work, because I really need to rewatch it - I don’t feel confident summarising it and its relevance to the theme right now lol</aside>

I have a strange desire to see what happens next for humanity. 'I’ get to bear witness to this brief… maybe 70, 80 years if average life expectancy stays where it is. I can absorb as much information as I can into the whorls of my brain’s neural network, encode it in various communicable forms so that what I have learned and what I value can outlive me. but once I’m gone, only memories of me and artefacts I have left behind can continue to affect the world. I might still have a distinguishable causal effect on the world in decades, perhaps hundreds of years after I’m gone. after that my existence is indistinguishable from noise. and subjective-experience wise, I don’t get to see it anyway!

but what if I didn’t go? what if we got to live forever?<!-- more -->

when I imagine getting to see the far future, I imagine the current me getting to see it, as if I got to step in a time machine. but the creature I become will be native to that time period.

let us imagine the set of states available to a brain. we can provisionally think of it comprising a dynamics model and stores of information such as memories, but that might prove insufficient. regardless: these things in combination learn to build an approximate model of the outside world and my place in it. they evolve with time. storing new memories causes older ones to decay gradually. the dynamics model is reinforced by the habits of thinking it performs.

it is a theorem that a one-dimensional system undergoing a random walk will eventually visit every possible state available to it an infinite number of times. but <a href="https://en.wikipedia.org/wiki/Random_walk#Higher_dimensions">a</a> <em><a href="https://en.wikipedia.org/wiki/Random_walk#Higher_dimensions">3D</a></em> <a href="https://en.wikipedia.org/wiki/Random_walk#Higher_dimensions">system is only 34% likely to return to its starting point</a>, and an N-dimensional system becomes increasingly unlikely to ever return there as the dimensions increase. moreover, any two points undergoing a random walk in a high-dimensional space will grow infinitely far apart in the same way.

if we imagine the evolution of the brain as being like a random walk (perhaps through some lower-dimensional latent space rather than the space of all possible neuron firings, except the latent space and architecture may well change as the brain learns new environments and the possibility to self-modify comes into existence)… I guess that means that in the <em>long durée</em>, 'I’ will become increasingly alien to the current me, and also everyone I know presently. what difference does it make that one person in a hundred thousand years has a special causal chain leading back to the 'me’ that exists now, and another doesn’t?

you could say there is some anchor or attractor in the space, some persistent life goal or set of values or 'inner law’, which you would orbit even as the world transforms drastically around you. we try to stay consistent with ourselves, after all. but my experience is: dubious. I have changed a lot in some ways, less so in others; themes from when I was a lot younger seem to recur unexpectedly. I can read a story I wrote a decade ago and still recognise the voice of it. but it feels like it is a set of different timescales of change rather than anything being fundamentally <em>immutable</em>.

replication, attractor states, the nebulous goal-seeking structures that are being called 'diverse intelligence’: these things can keep a pattern around. but only so long.

in one timeline, I die at a distinct point: all the processes shut down more or less at once, the organising principle decoheres, and the assembly of matter ceases to be <em>an organism</em> as it was just a moment earlier. in another timeline, 'I’ disappear gradually as memories are overwritten and by brain learns to act differently; there is no definite point where I definitively cease to be the same person.

(some human relationships end abruptly, such as in a big fight, or a death. others end through a gradual divergence. I have experienced this many times in even the short period I’ve been alive. sometimes though, a stable feedback loop keeps the two people close over a very long period, even as they change. these feel special, they accumulate far more memories, they are more painful if they break. two or more humans might live happily together for 70 years, easily enough. but could a relationship last <em>indefinitely</em>? over <em>billions of years</em>?)

so what sort of mind could take it all in? comprehend <em>all</em> the different eras and forms?

I think about associative memory. to crudely oversimplify, we consolidate and store short-term memories accumulated through a day <a href="https://www.youtube.com/watch?v=ceFFEmkxTLg">during sleep</a> into a long-term form. kirsanov says they go into the neocortex but I am not sure this is as settled as I thought; it doesn’t really matter. when awake, we retrieve memories associatively: something will 'remind you of’ something else that might be relevant. however, it would follow that only so much information can be retrieved for processing at once.

to make the inevitable analogy to artificial neural networks and computers, we don’t have anything so simple or precise as a 'context window’, but at any given time I feel like there must be only so much 'bandwidth’ to pull in additional memories into the working memory 'cache’. imagine if you could have a vast 'library’ of semantic and episodic memories, and look up something relevant very quickly, but you can only 'read one book’ (or a few books) at a time. and the way you think and behave depends significantly on the books you pull out.

at that point you have to be a creature who can perform many different 'characters’. you might have memories of both, but your 25th-century-sona might be very different from your 41st-century-sona. you are sort of inescapably plural. shoggoth wearing a mask, etc. etc., you know where I’m going with this.

is this necessary? would it be possible to have a 'brain’ that can consider vastly more information at once in parallel, like the planet-running Minds in Iain M Banks? or is there some kind of linear bottleneck, the putative 'main thread’ which may or may not be identifiable with 'consciousness’? even without a bottleneck, it takes time for information to propagate. you could pile neurons onto a brain, letting its broad plasticity adapt them to whatever function it might need, but at some point it’s more like a vast space where multiple 'wavelets’ of collective thought-excitation are moving around and interacting with each other than a unified thing.

but perhaps that is no obstacle: perhaps a process in there could just duplicate instances of itself and have some mechanism to reconcile them periodically and pass information between these units, and the whole thing can be a nice little universe-contemplating superorganism. <small>until some nodes start to defect.</small> but oh dangit, we just invented multicellularity again. and GPUs. and… human society?

so perhaps that’s the resolution to my little wish: this little 'node’ right here may only be able to consider the parts of history that it’s exposed to, but it’s a component in a larger system. it can receive compressed representations of thoughts from other nodes, and send them in turn. we call that 'language’. that’s what you’re reading right now, hi!

well, that’s nice and pretty and all, but it still leaves us with entropy and the arrow of time. maybe the <em>superorganism</em> will eventually see the whole future, but its older memories still decay, and <em>I</em> am not the superorganism.

in the absence of a total perspective vortex, then… without the means to know 'halloween’…

well, that leaves constructing fantasies of it, as an artistic gesture, a game to play in the present. it will absolutely certainly get everything wrong and one day feel as dated as Zager and Evans. it still calls to me, though - to fully dissolve what is familiar, and take no arbitrary assumption. who can say why.